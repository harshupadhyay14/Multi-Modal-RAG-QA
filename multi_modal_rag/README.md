# ğŸ“˜ Multi-Modal RAG QA System  
A Retrieval-Augmented Generation (RAG) system that extracts **text**, **tables**, and **images** from PDFs, applies **OCR**, generates **embeddings**, indexes them using **FAISS**, and answers user questions using **Groq LLaMA 3.3** models.  
Built as part of the **Wasserstoff Gen-AI Internship Qualification Task**.

---

## ğŸš€ Features

### ğŸ” **1. Multi-Modal PDF Ingestion**
- Extracts **text**, **tables**, and **images**  
- Supports scanned PDFs (OCR enabled)  
- Handles noisy PDFs gracefully  

### ğŸ§  **2. OCR Pipeline**
- Primary: **Paddle OCR** (optional, auto-disabled if unavailable)  
- Fallback: **Tesseract OCR** (installed via apt)  

### ğŸ§© **3. Chunking**
- Splits extracted content into overlapping, context-preserving chunks  
- Separate chunk logic for:
  - text blocks  
  - table data  
  - OCR outputs  

### ğŸ”¢ **4. Embeddings**
- Uses **Sentence Transformers** (`all-mpnet-base-v2`)  
- Generates dense vector embeddings for all chunks  

### ğŸ” **5. Vector Search (FAISS)**
- Fast approximate nearest neighbor (ANN) search  
- Retrieves top-k relevant chunks based on cosine similarity  

### ğŸ¤– **6. Groq LLM Answering**
- Uses **Groq LLaMA-3.3-70B-Versatile**  
- Produces grounded answers **only from document context**  
- Includes **page-level citations**  

### ğŸŒ **7. Streamlit UI**
- Upload PDF  
- See extraction status  
- Ask questions  
- Get citation-backed answers  

---

## ğŸ—ï¸ System Architecture
# ğŸ“˜ Multi-Modal RAG QA System  
A Retrieval-Augmented Generation (RAG) system that extracts **text**, **tables**, and **images** from PDFs, applies **OCR**, generates **embeddings**, indexes them using **FAISS**, and answers user questions using **Groq LLaMA 3.3** models.  
Built as part of the **Wasserstoff Gen-AI Internship Qualification Task**.

---

## ğŸš€ Features

### ğŸ” **1. Multi-Modal PDF Ingestion**
- Extracts **text**, **tables**, and **images**  
- Supports scanned PDFs (OCR enabled)  
- Handles noisy PDFs gracefully  

### ğŸ§  **2. OCR Pipeline**
- Primary: **Paddle OCR** (optional, auto-disabled if unavailable)  
- Fallback: **Tesseract OCR** (installed via apt)  

### ğŸ§© **3. Chunking**
- Splits extracted content into overlapping, context-preserving chunks  
- Separate chunk logic for:
  - text blocks  
  - table data  
  - OCR outputs  

### ğŸ”¢ **4. Embeddings**
- Uses **Sentence Transformers** (`all-mpnet-base-v2`)  
- Generates dense vector embeddings for all chunks  

### ğŸ” **5. Vector Search (FAISS)**
- Fast approximate nearest neighbor (ANN) search  
- Retrieves top-k relevant chunks based on cosine similarity  

### ğŸ¤– **6. Groq LLM Answering**
- Uses **Groq LLaMA-3.3-70B-Versatile**  
- Produces grounded answers **only from document context**  
- Includes **page-level citations**  

### ğŸŒ **7. Streamlit UI**
- Upload PDF  
- See extraction status  
- Ask questions  
- Get citation-backed answers  

---

## ğŸ—ï¸ System Architecture
PDF â†’ Extract Text/Tables/Images â†’ OCR â†’ Chunking â†’ Embeddings â†’ FAISS Index
â†“
Query Embedding
â†“
Retrieve Relevant Chunks
â†“
Groq LLM (LLaMA-3.3-70B) Generates Answer

## ğŸ“¦ Folder Structure
Multi-Modal-RAG-QA/
â”‚
â”œâ”€â”€ app/
â”‚ â””â”€â”€ streamlit_app.py # Main Streamlit UI
â”‚
â”œâ”€â”€ multi_modal_rag/
â”‚ â”œâ”€â”€ ingestion/
â”‚ â”‚ â”œâ”€â”€ pdf_ingest.py # PDF extraction pipeline
â”‚ â”‚ â”œâ”€â”€ ocr.py # OCR (Paddle + Tesseract fallback)
â”‚ â”‚ â””â”€â”€ table_extractor.py # Table extraction
â”‚ â”‚
â”‚ â”œâ”€â”€ chunking/
â”‚ â”‚ â””â”€â”€ chunker.py # Chunking logic
â”‚ â”‚
â”‚ â”œâ”€â”€ embeddings/
â”‚ â”‚ â””â”€â”€ embedder.py # SentenceTransformer embeddings
â”‚ â”‚
â”‚ â”œâ”€â”€ index/
â”‚ â”‚ â””â”€â”€ indexer.py # FAISS index for retrieval
â”‚ â”‚
â”‚ â””â”€â”€ llm/
â”‚ â””â”€â”€ generator.py # Groq LLaMA answer generator
â”‚
â”œâ”€â”€ requirements.txt
â”œâ”€â”€ apt.txt # System dependencies for HF Spaces
â”œâ”€â”€ README.md
â””â”€â”€ .streamlit/config.toml

---

## ğŸŒ Live Demo (Hugging Face Spaces)

ğŸ”— **[Add your Spaces link here once deployed]**

---

## ğŸ› ï¸ Installation & Running Locally

### 1ï¸âƒ£ Clone the repo
```bash
git clone https://github.com/<harshupadhyay14>/Multi-Modal-RAG-QA.git
cd Multi-Modal-RAG-QA

2ï¸âƒ£ Create virtual environment
python -m venv venv
source venv/bin/activate   # macOS/Linux
venv\Scripts\activate      # Windows

3ï¸âƒ£ Install dependencies
pip install -r requirements.txt

4ï¸âƒ£ Run Streamlit UI
streamlit run app/streamlit_app.py
